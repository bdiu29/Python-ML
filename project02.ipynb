{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"colab":{"name":"project02.ipynb","provenance":[{"file_id":"1ZxqOkizv_it3bMT6t6nJ_EfI1Uo6miS4","timestamp":1636253855818}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"estwgLqaatLs"},"source":["*Python Machine Learning 3rd Edition* by [Sebastian Raschka](https://sebastianraschka.com), Packt Publishing Ltd. 2019\n","\n","Code Repository: https://github.com/rasbt/python-machine-learning-book-3rd-edition\n","\n","Code License: [MIT License](https://github.com/rasbt/python-machine-learning-book-3rd-edition/blob/master/LICENSE.txt)"]},{"cell_type":"markdown","metadata":{"id":"MSKhooNwatLv"},"source":["# Python Machine Learning - Code Examples"]},{"cell_type":"markdown","metadata":{"id":"eM44W4PzTHhQ"},"source":["# Notebook Setup"]},{"cell_type":"markdown","metadata":{"id":"b6iWgQnbnBTj"},"source":["When you are done with this notebook, run the following code cell to unmount Google Drive"]},{"cell_type":"code","metadata":{"id":"D78AM1fFt2ty"},"source":["from google.colab import drive\n","drive.flush_and_unmount()\n","print('All changes made in this colab session should now be visible in Drive.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zPzhOpDUvfAL"},"source":["The following code cell installs additional dependencies required to run the Jupyter Notebooks used in this class."]},{"cell_type":"code","metadata":{"id":"qjPAPnLLTN4x"},"source":["# Add additional Python packages that we will be using in class\n","!apt install graphviz build-essential checkinstall imagemagick\n","# Base Python packages to run example Jupyter Notebooks\n","!pip install watermark pyprind mlxtend\n","# Python packages to visualize Decision Tree Classifiers\n","!pip install pydotplus graphviz pyparsing\n","# Python packages for Natrual Language Processing\n","!pip install nltk\n","# Python packages for Flask-based web applications\n","!pip install flask wtforms\n","# Python packages for TensorFlow\n","!pip install tensorflow tensorflow-datasets"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R0UX1g1_gQHP"},"source":["The following code cell defines a variable equal to the location inside your Google Drive where you copied the ch03 folder"]},{"cell_type":"code","metadata":{"id":"ETNDrge2gQHW"},"source":["##### TODO CHANGE THIS TO THE PATH IN GOOGLE DRIVE WHERE YOU COPIED THE ch03 FOLDER #####\n","google_drive_root='/Colab Notebooks/Project02'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q1uDwAzrhfmC"},"source":["google_drive_mount_location = '/content/drive'\n","google_file_prefix=google_drive_mount_location + '/My Drive/' + google_drive_root + '/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-6HBVmy6fmNx"},"source":["The following code cell mounts your Google Drive into the runtime of the workbook, so that you can access files."]},{"cell_type":"code","metadata":{"id":"8CRN2nETfghz"},"source":["# Read more here: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=D78AM1fFt2ty\n","from google.colab import drive\n","drive.mount(google_drive_mount_location)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqnB7hp2_Xms"},"source":["import os\n","os.chdir(google_file_prefix)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WXjXV45xatLv"},"source":["# Project 2: Sentiment Analysis - Amazon Product Reviews"]},{"cell_type":"markdown","metadata":{"id":"XWCdaZqgatMJ"},"source":["# **1. Experiment Objective**\n","The objective of this experiment is to train an machine learning model on Amazon product reviews.\n","\n","# **TOS information:**\n","\n","Amazon Product Reviews from Kaggle\n","\n","https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products\n","\n","Okay to use for academic purposes.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EFebP_K6r_a4"},"source":["# **Data Collection**"]},{"cell_type":"code","metadata":{"id":"hEJjeAIjjtCs"},"source":["import numpy as np\n","import pandas as pd\n","\n","df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Project02/Amazon_Reviews.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5m78DKWnncA1"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F-fP5zDAtPFw"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PnQiONbasE_4"},"source":["# **Data Preprocessing**"]},{"cell_type":"code","metadata":{"id":"OA4E-Oymo-CQ"},"source":["df.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8qnR4cK2Oz1"},"source":["df = df[['reviews.rating','reviews.text']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gP1Plf3J2kdO"},"source":["df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GI-syT73nciF"},"source":["df.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WVjknVWJ5mhf"},"source":["df = df.dropna(axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DGtHWIk6iG-"},"source":["df.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dLibUaopDQKx"},"source":["**Label encoding the sentiment column 'reviews.rating'**"]},{"cell_type":"code","metadata":{"id":"VLXxz4qQAjIU"},"source":["sentiment = {1: 0, 2: 0, 3: 0, 4: 1, 5: 1}\n","\n","df['sentiment']=df['reviews.rating'].map(sentiment)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1LxqxsI_Jo1z"},"source":["df['sentiment'].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DNi-OqllAqmq"},"source":["df['sentiment'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wJZCAO7olG4a"},"source":["df = df.drop('reviews.rating',axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTi0CKZYlSVj"},"source":["df.rename(columns={\"reviews.text\":\"review\"} ,inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YXMS45-2lPO8"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CXyEC6xfm5Ya"},"source":["**Save a cleaned copy to a csv.**"]},{"cell_type":"code","metadata":{"id":"OWH0Punbk8oJ"},"source":["df.to_csv('/content/drive/MyDrive/Colab Notebooks/Project02/ama_data.csv', index=False, encoding='utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NYgN5bde7_lH"},"source":["## **Cleaning text data**"]},{"cell_type":"code","metadata":{"id":"l24oRbJjqyon"},"source":["import re\n","def preprocessor(text):\n","    text = re.sub('<[^>]*>', '', text)\n","    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n","                           text)\n","    text = (re.sub('[\\W]+', ' ', text.lower()) +\n","            ' '.join(emoticons).replace('-', ''))\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A5X8T7zkqzv2"},"source":["df['review'] = df['review'].apply(preprocessor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E6M0_xxfxL8I"},"source":["df['review'][0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gi43cCeBatL9"},"source":["## **Processing words into tokens**"]},{"cell_type":"code","metadata":{"id":"tH39PcEeRaqu"},"source":["from nltk.stem.porter import PorterStemmer\n","\n","porter = PorterStemmer()\n","\n","def tokenizer(text):\n","    return text.split()\n","\n","\n","def tokenizer_porter(text):\n","    return [porter.stem(word) for word in text.split()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gS5gGKYZwlXv"},"source":["import pandas as pd\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","\n","nltk.download('stopwords')\n","\n","df['review'] = df['review'].apply(word_tokenize)\n","stop = stopwords.words('english')\n","df['review'] = df['review'].apply(lambda words: [word for word in words if word not in stop])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A9_1Ssr8UYGP"},"source":["df['review'][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jPsKvy2bxhH4"},"source":["df['review'] = df['review'].astype(str)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n29dElfiI4L-"},"source":["df['review'][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MnSaLAwDTZY2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nc04uIetHGnw"},"source":["## **Constructing a TF-IDF Vectorizer**"]},{"cell_type":"code","metadata":{"id":"OyEnIDWLHGJH"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","vectorizer = TfidfVectorizer(max_features=5000)\n","vectorizer.fit(df['review'])\n","features = vectorizer.transform(df['review'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vjGNHYsQI-eR"},"source":["tf_idf = pd.DataFrame(features.toarray(), columns=vectorizer.get_feature_names())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HcW9OmRJH4i"},"source":["tf_idf.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i3DH1gGkzY6q"},"source":["# **Model Training**"]},{"cell_type":"code","metadata":{"id":"Ms5vGaK_tmTh"},"source":["X = df['review']\n","y = df['sentiment']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pM6-XjwGyoH2"},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ae15-awyqs_"},"source":["from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import SGDClassifier\n","\n","from sklearn.model_selection import GridSearchCV\n","\n","tfidf = TfidfVectorizer(strip_accents=None,\n","                        lowercase=False,\n","                        preprocessor=None)\n","\n","# loss = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n","penalty = ['l2','l1']\n","alpha = [0.001, 0.01, 0.1]\n","\n","\n","param_grid = [{'vect__ngram_range': [(1, 1),(1,2)],\n","               'vect__stop_words': [stop],\n","               'vect__tokenizer': [tokenizer],\n","               'clf__penalty': penalty,\n","               'clf__alpha': alpha},\n","              {'vect__ngram_range': [(1, 1), (1,2)],\n","               'vect__stop_words': [stop],\n","               'vect__tokenizer': [tokenizer],\n","               'vect__use_idf':[True, False],\n","               'vect__norm':[None],\n","               'clf__penalty': penalty,\n","               'clf__alpha': alpha},\n","              ]\n","\n","sgd_tfidf = Pipeline([('vect', tfidf),\n","                     ('clf', SGDClassifier(random_state=0, loss='hinge'))])\n","\n","gs_sgd_tfidf = GridSearchCV(sgd_tfidf, param_grid,\n","                           scoring='accuracy',\n","                           cv=5,\n","                           verbose=2,\n","                           n_jobs=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iPYIHrMnatL_"},"source":["gs_sgd_tfidf.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F6l8T9EyatMA"},"source":["print('Best parameter set: %s ' % gs_sgd_tfidf.best_params_)\n","print('CV Accuracy: %.3f' % gs_sgd_tfidf.best_score_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b-7RsIjUatMA"},"source":["clf = gs_sgd_tfidf.best_estimator_\n","print('Test Accuracy: %.3f' % clf.score(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T6NuvUkrL6g4"},"source":["**Optimal hyperparameters found**\n","\n","{'clf__alpha': 0.001, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__use_idf': False}\n","\n","**Now to fit the SGD classifier on these hyperparameters and pickle the file for out-of-core learning**"]},{"cell_type":"code","metadata":{"id":"bYWVBZN2N7Xq"},"source":["vectorizer = TfidfVectorizer(ngram_range= (1,2), norm=None, use_idf=True, strip_accents=None, lowercase=False, preprocessor=None, max_features = 5000)\n","vectorizer.fit(df['review'])\n","features = vectorizer.transform(df['review'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rx0GXY4lO206"},"source":["tfidf = pd.DataFrame(features.toarray(), columns=vectorizer.get_feature_names())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ss0Dl92BO_ij"},"source":["tfidf.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t7xkT3cFPGhC"},"source":["from sklearn.linear_model import SGDClassifier\n","sgd = SGDClassifier(alpha = 0.001,penalty = 'l2', random_state=0, loss='hinge')\n","clf = sgd.partial_fit(tfidf, df['sentiment'],classes=df['sentiment'].unique())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZzXsR_4lZqDd"},"source":["Model fitted against entire dataset. Now to pickle the resulting file."]},{"cell_type":"code","metadata":{"id":"2G2TRgLPa3tl"},"source":["import pickle\n","import os\n","\n","dest = os.path.join(google_file_prefix + 'amazonclassifier', 'pkl_objects')\n","if not os.path.exists(dest):\n","    os.makedirs(dest)\n","\n","pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'), protocol=4)   \n","pickle.dump(clf, open(os.path.join(dest, 'amazonclassifier.pkl'), 'wb'), protocol=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFbXscAba3tl"},"source":["import pickle\n","import os\n","\n","dest = os.path.join(google_file_prefix + 'amazonclassifier_with_update', 'pkl_objects')\n","if not os.path.exists(dest):\n","    os.makedirs(dest)\n","\n","pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'), protocol=4)   \n","pickle.dump(clf, open(os.path.join(dest, 'amazonclassifier.pkl'), 'wb'), protocol=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-H1eCp0Wc1MD"},"source":["import os\n","os.chdir(google_file_prefix)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvZqiwQLUUeg"},"source":["%%writefile amazonclassifier/vectorizer.py\n","from sklearn.feature_extraction.text import HashingVectorizer\n","import re\n","import os\n","import pickle\n","\n","cur_dir = os.path.dirname(__file__)\n","stop = pickle.load(open(os.path.join(\n","                cur_dir,\n","                'pkl_objects', \n","                'stopwords.pkl'), 'rb'))\n","\n","def tokenizer(text):\n","    text = re.sub('<[^>]*>', '', text)\n","    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n","                           text.lower())\n","    text = re.sub('[\\W]+', ' ', text.lower()) \\\n","                   + ' '.join(emoticons).replace('-', '')\n","    tokenized = [w for w in text.split() if w not in stop]\n","    return tokenized\n","\n","vect = HashingVectorizer(decode_error='ignore',\n","                         n_features=2**21,\n","                         preprocessor=None,\n","                         ngram_range = (1,2),\n","                         norm = None,\n","                         use_idf=True,\n","                         tokenizer=tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_LVqSgOHa3tm"},"source":["import os\n","os.chdir(google_file_prefix + 'amazonclassifier')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6JyktUoa3tm"},"source":["import pickle\n","import re\n","import os\n","from vectorizer import vect\n","\n","clf = pickle.load(open(os.path.join('pkl_objects', 'amazonclassifier.pkl'), 'rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4tFAcKNDa3tn"},"source":["import numpy as np\n","label = {0:'negative', 1:'positive'}\n","\n","example = [\"I love this movie. It's amazing.\"]\n","X = vect.transform(example)\n","print('Prediction: %s\\nProbability: %.2f%%' %\n","      (label[clf.predict(X)[0]], \n","       np.max(clf.predict_proba(X))*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h1kfB_It38Am"},"source":["# **Setting up SQLite**"]},{"cell_type":"code","metadata":{"id":"wnb7uJnZa3to"},"source":["os.getcwd()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C8GSJUlSa3to"},"source":["import sqlite3\n","import os\n","\n","conn = sqlite3.connect('reviews.sqlite')\n","c = conn.cursor()\n","\n","c.execute('DROP TABLE IF EXISTS review_db')\n","c.execute('CREATE TABLE review_db (review TEXT, sentiment INTEGER, date TEXT)')\n","\n","example1 = 'I love this movie'\n","c.execute(\"INSERT INTO review_db (review, sentiment, date) VALUES (?, ?, DATETIME('now'))\", (example1, 1))\n","\n","example2 = 'I disliked this movie'\n","c.execute(\"INSERT INTO review_db (review, sentiment, date) VALUES (?, ?, DATETIME('now'))\", (example2, 0))\n","\n","conn.commit()\n","conn.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mIZ-TWFda3tp"},"source":["conn = sqlite3.connect('reviews.sqlite')\n","c = conn.cursor()\n","\n","c.execute(\"SELECT * FROM review_db WHERE date BETWEEN '2017-01-01 10:10:10' AND DATETIME('now')\")\n","results = c.fetchall()\n","\n","conn.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iEVZarVb6QNI"},"source":["print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zBAF8Ye_a3ts"},"source":["## **Updating the movie review classifier**"]},{"cell_type":"markdown","metadata":{"id":"VBqyiq9wa3ts"},"source":["Let us make and operate on a copy of the movieclassifier subdirectory (this should already exist when you downloaded this GitHub repo (otherwise, please duplicate the `movieclassifier` directory)."]},{"cell_type":"code","metadata":{"id":"fLOSdUz7a3ts"},"source":["import shutil\n","\n","os.chdir('..')\n","\n","if not os.path.exists('amazonclassifier_with_update'):\n","    os.mkdir('amazonclassifier_with_update')\n","os.chdir('amazonclassifier_with_update')\n","\n","if not os.path.exists('pkl_objects'):\n","    os.mkdir('pkl_objects')\n","\n","shutil.copyfile('../amazonclassifier/pkl_objects/amazonclassifier.pkl',\n","                './pkl_objects/amazonclassifier.pkl')\n","\n","shutil.copyfile('../amazonclassifier/reviews.sqlite',\n","                './reviews.sqlite')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xrA6nY6fa3ts"},"source":["Define a function to update the classifier with the data stored in the local SQLite database:"]},{"cell_type":"code","metadata":{"id":"Mhc6idSEa3tt"},"source":["import pickle\n","import sqlite3\n","import numpy as np\n","\n","# import HashingVectorizer from local dir\n","from vectorizer import vect\n","\n","def update_model(db_path, model, batch_size=10000):\n","\n","    conn = sqlite3.connect(db_path)\n","    c = conn.cursor()\n","    c.execute('SELECT * from review_db')\n","    \n","    results = c.fetchmany(batch_size)\n","    while results:\n","        data = np.array(results)\n","        X = data[:, 0]\n","        y = data[:, 1].astype(int)\n","    \n","        classes = np.array([0, 1])\n","        X_train = vect.transform(X)\n","        clf.partial_fit(X_train, y, classes=classes)\n","        results = c.fetchmany(batch_size)\n","    \n","    conn.close()\n","    return None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JyM0wPnZa3tt"},"source":["Update the model:"]},{"cell_type":"code","metadata":{"id":"DDZ6zkYAa3tt"},"source":["cur_dir = '.'\n","\n","# Use the following path instead if you embed this code into\n","# the app.py file\n","\n","# import os\n","# cur_dir = os.path.dirname(__file__)\n","\n","clf = pickle.load(open(os.path.join(cur_dir,\n","                 'pkl_objects',\n","                 'amazonclassifier.pkl'), 'rb'))\n","db = os.path.join(cur_dir, 'reviews.sqlite')\n","\n","update_model(db_path=db, model=clf, batch_size=10000)\n","\n","# Uncomment the following lines to update your classifier.pkl file\n","\n","# pickle.dump(clf, open(os.path.join(cur_dir, \n","#             'pkl_objects', 'classifier.pkl'), 'wb')\n","#             , protocol=4)"],"execution_count":null,"outputs":[]}]}